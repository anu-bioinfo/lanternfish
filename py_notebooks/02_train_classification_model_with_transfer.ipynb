{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'motcube_preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1b728102827c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m '''\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmotcube_preprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'motcube_preprocessing'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train a classification CNN with transfer learning\n",
    "\n",
    "This notebook outlines how to train a CNN classifier \n",
    "to discriminate between cell types by first initializing\n",
    "the network with weights from a simulated data\n",
    "classifier, as trained in 01_train_classification_model\n",
    "'''\n",
    "\n",
    "from motcube_preprocessing import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, CSVLogger\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "# Lanternfish models are stored in bestiary\n",
    "# multicontextL classifies an arbitrary number of classes using stacked\n",
    "# 3D-convolutional layers\n",
    "from bestiary import multi_contextL as model_fcn\n",
    "# Keras contains a function to load saved models in one-line!\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a learning rate schedule function\n",
    "# and set the optimizer\n",
    "def lr_schedule(rate=0.01, decay=0.8):\n",
    "    '''\n",
    "    Generates a schedule function with exp decay\n",
    "\n",
    "    alpha_new = alpha_init * decay_coeff^epoch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rate : float.\n",
    "        learning rate.\n",
    "    decay : float.\n",
    "        decay coefficient\n",
    "    '''\n",
    "    def sched(epoch):\n",
    "        return (rate * (decay**np.int(epoch)))\n",
    "    return sched\n",
    "\n",
    "sched = lr_schedule(rate = 0.005, decay = 0.8)\n",
    "sgd = SGD(momentum = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set directory and file information\n",
    "\n",
    "# path to pretrained model\n",
    "trained_model_path = 'nets/20170315_multiclass_bin_disk25.h5'\n",
    "\n",
    "# paths to new cell data\n",
    "train_dir = '/media/jkimmel/HDD0/myctophid/cell_data/train'\n",
    "val_dir = '/media/jkimmel/HDD0/myctophid/cell_data/val'\n",
    "nb_classes = 2\n",
    "batch_size = 8\n",
    "cube_size = (216,216,76)\n",
    "file_name_save = 'mef_wt_v_mr_no_transfer.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set training callbacks for keras .fit_generator() \n",
    "#\n",
    "# ModelCheckpoint saves model with lowest val loss\n",
    "# LearningRateScheduler applies the scheduling function\n",
    "# EarlyStopping halts training if val loss stops improving\n",
    "# CSVLogger writes training data to a CSV\n",
    "callbacks = [ModelCheckpoint(file_name_save, monitor = 'val_loss', verbose = 0, save_best_only = True, mode = 'auto'),\n",
    "    LearningRateScheduler(sched),\n",
    "    EarlyStopping(monitor='val_loss', patience=3),\n",
    "    CSVLogger(filename=file_name_save[:-3]+'_train_log.csv', separator=',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate data generators\n",
    "# NOTE: here we use the horizontal_flip and vertical_flip\n",
    "# features of MotcubeDataGenerator to diversify our small\n",
    "# sample set with non-destructive permutations\n",
    "mcgen = MotcubeDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "mc_generator = mcgen.flow_from_directory(train_dir, class_mode = 'categorical', color_mode='grayscale', target_size = cube_size, batch_size = batch_size)\n",
    "valgen = MotcubeDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
    "val_generator = valgen.flow_from_directory(val_dir, class_mode = 'categorical', color_mode='grayscale', target_size = cube_size, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize and compile the model\n",
    "model = model_fcn(batch_size = batch_size, nb_classes = 3, nb_channels=1, image_x=cube_size[0], image_y=cube_size[1], image_z=cube_size[2])\n",
    "model.compile(optimizer=sgd, metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've instantiated our new classification model, we need to transfer weights learned by our pretrained model. Transfer learning allows for features learned in one task to be carried over as the initialization of another, speeding up or enabling otherwise untractable learning problems.\n",
    "\n",
    "Here, we'll transfer weights learned by classifying our large simulated motion data set to a new model, which will classify our much smaller real cell motility data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the pretrained model \n",
    "pretrain_model = load_model(trained_model_path)\n",
    "# get weights from the pretrained and new network\n",
    "w0 = pretrain_model.get_weights()\n",
    "w1 = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final layers of the network are fully connected *Dense* layers, so the number of parameters will change if the size of the cube input changes.\n",
    "\n",
    "Here, the cubes are now larger than the original `(156, 156, 101)` simulated cubes, so we can't transfer weights from the first Dense layer. \n",
    "\n",
    "The final Dense layers also has units `n = nb_classes`, so our 3 class simulated motion network has one more parameter than the new 2 class real cell data network.\n",
    "\n",
    "To remedy this, we only transfer the top convolutional layer weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transfer conv layer weights and apply to the model\n",
    "w = w0\n",
    "w[16:] = w1[16:] # Dense layers are different sizes, use different weights\n",
    "model.set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "hist = model.fit_generator(mc_generator, samples_per_epoch=mc_generator.nb_sample, nb_epoch=30, callbacks=callbacks, validation_data=val_generator, nb_val_samples=val_generator.nb_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
