{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Train a Lanternfish autoencoder model\n",
    "\n",
    "Lanternfish includes networks to learn representations of feature space \n",
    "based on 3D spatial representations of trajectories in 2 dimensions.\n",
    "\n",
    "This notebook outlines how to train an autoencoder on simulated \n",
    "random walk, power flier, and fractal Brownian motion data.\n",
    "'''\n",
    "from motcube_preprocessing import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, CSVLogger\n",
    "import numpy as np\n",
    "\n",
    "# Lanternfish includes multiple autoencoder models, utilizing stacked\n",
    "# 3D-convolutions, max-pooling, and upsampling layers\n",
    "# motcube_ae is a motion cube autoencoder for (156,156,100) cubes\n",
    "# ZeroPadding layers can be altered to accomodate alternative sizes\n",
    "from bestiary import motcube_ae as model_fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a wrapper to provide data generator inputs as the desired output\n",
    "def auto_gt_generator(generator):\n",
    "    '''\n",
    "    Wraps a generator to provide the same output twice in a tuple\n",
    "    Useful for training with input as ground truth\n",
    "    '''\n",
    "    for batch in generator:\n",
    "        yield (batch, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set directories containing training and val data\n",
    "train_dir = '/path/to/ae_data/train'\n",
    "val_dir = '/path/to/ae_data/val'\n",
    "# Set training parameters\n",
    "batch_size = 12\n",
    "cube_size = (156,156,100)\n",
    "file_name_save = 'autoencoder.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set model callbacks\n",
    "callbacks = [ModelCheckpoint(file_name_save, monitor = 'val_loss', verbose = 0, save_best_only = True, mode = 'auto'),\n",
    "    LearningRateScheduler(sched),\n",
    "    EarlyStopping(monitor='val_loss', patience=3),\n",
    "    CSVLogger(filename=file_name_save[:-3]+'_train_log.csv', separator=',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate data generator objects using MotcubeDataGenerator()\n",
    "mcgen = MotcubeDataGenerator()\n",
    "mc_generator = mcgen.flow_from_directory(train_dir, class_mode = None, color_mode='grayscale', target_size = cube_size, batch_size = batch_size)\n",
    "valgen = MotcubeDataGenerator()\n",
    "val_generator = valgen.flow_from_directory(val_dir, class_mode = None, color_mode='grayscale', target_size = cube_size, batch_size = batch_size)\n",
    "\n",
    "# Wrap generators so input is returned as desired output\n",
    "train_ae_gen = auto_gt_generator(mc_generator)\n",
    "val_ae_gen = auto_gt_generator(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile and fit model\n",
    "model = model_fcn(batch_size = batch_size, nb_channels=1, image_x=cube_size[0], image_y=cube_size[1], image_z=cube_size[2])\n",
    "\n",
    "# NOTE: binary_crossentropy is only applicable as a loss function if the inputs\n",
    "# use binary representations\n",
    "# For motcubes using non-binary kernels, change the loss to 'mse'\n",
    "# (mean squared error)\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "hist = model.fit_generator(train_ae_gen, samples_per_epoch=mc_generator.nb_sample//2, nb_epoch=30, callbacks=callbacks, validation_data=val_ae_gen, nb_val_samples=val_generator.nb_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
