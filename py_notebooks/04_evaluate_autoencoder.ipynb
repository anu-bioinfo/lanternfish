{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluate a Lanternfish autoencoder\n",
    "\n",
    "Lanternfish uses autoencoders to learn representation of a motion feature\n",
    "space in an unsupervised manner. \n",
    "\n",
    "This notebook outlines how to obtain autoencoder outputs for visualization.\n",
    "'''\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from motcube_preprocessing import *\n",
    "from scipy.io import savemat\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set directories\n",
    "model_path = '/path/to/model.h5'\n",
    "input_dir = '/path/to/input/images'\n",
    "save_dir = '/path/to/output'\n",
    "# Set model parameters\n",
    "exp_name = 'exp_name'\n",
    "batch_size = 3\n",
    "cube_size = (156,156,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define autoencoder data generator wrapper\n",
    "def auto_gt_generator(generator):\n",
    "    '''\n",
    "    Wraps a generator to provide the same output twice in a tuple\n",
    "    Useful for training with input as ground truth\n",
    "    '''\n",
    "    for batch in generator:\n",
    "        yield (batch, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate data generators\n",
    "valgen = MotcubeDataGenerator()\n",
    "val_generator = valgen.flow_from_directory(input_dir, class_mode = None, color_mode='grayscale', target_size=cube_size, batch_size = batch_size)\n",
    "ae_gen = auto_gt_generator(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate a single batch of images\n",
    "x = next(val_generator)\n",
    "evaluate_model = K.function(\n",
    "    [model.layers[0].input, K.learning_phase()],\n",
    "    [model.layers[-1].output]\n",
    "    )\n",
    "y = evaluate_model([x, 0])[0]\n",
    "\n",
    "# y may be exported using scipy.io.savemat for visualization with matlab\n",
    "savemat(os.path.join(save_dir, exp_name + '_ae_io.mat'), mdict = {'x' : x, 'y' : y})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
