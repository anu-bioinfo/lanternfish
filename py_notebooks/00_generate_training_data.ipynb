{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generate training data for analysis with Lanternfish\n",
    "\n",
    "Lanternfish represents motion as a 3D image with dimensions\n",
    "x, y, and time (t). These images are referred to as 'motion cubes'.\n",
    "These cubes are saved as 3D numpy arrays in compressed .npz archives.\n",
    "\n",
    "As input, you'll need X and Y coordinates for each object stored\n",
    "in an N x T CSV, where N is the number of objects and T is the number of\n",
    "time steps. One CSV stores X coordinates and another Y coordinates.\n",
    "i.e.) tracksX(i, t) represents the object i's X coordinate at time t. \n",
    "\n",
    "This notebook outlines how to generate 3D motion cubes from simulated\n",
    "random walk, power flier, and fractal Brownian motion paths.\n",
    "'''\n",
    "import numpy as np\n",
    "from motion_cube import motion_cube, crop_tracks, gauss_kernel\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import gaussian\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set directory locations\n",
    "save_dir = '/path/to/save/motioncubes/'\n",
    "rw_dir = os.path.join(save_dir, 'rw_cubes')\n",
    "pf_dir = os.path.join(save_dir, 'pf_cubes')\n",
    "fbm_dir = os.path.join(save_dir, 'fbm_cubes')\n",
    "# Set the compression factor\n",
    "# Compression is necc. due to GPU memory restrictions\n",
    "# Up to 4X compression doesn't appear to inhibit training\n",
    "fold_compression = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load paths\n",
    "rw_x = np.loadtxt('sim_data/rw_X_100k.csv', delimiter=',')\n",
    "rw_y = np.loadtxt('sim_data/rw_Y_100k.csv', delimiter=',')\n",
    "pf_x = np.loadtxt('sim_data/pf_X_100k.csv', delimiter=',')\n",
    "pf_y = np.loadtxt('sim_data/pf_Y_100k.csv', delimiter=',')\n",
    "fbm_x = np.loadtxt('sim_data/fBm_X_100k.csv', delimiter=',')\n",
    "fbm_y = np.loadtxt('sim_data/fBm_Y_100k.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compress paths\n",
    "rw_x = rw_x / fold_compression\n",
    "rw_y = rw_y / fold_compression\n",
    "pf_x = pf_x / fold_compression\n",
    "pf_y = pf_y / fold_compression\n",
    "# fBm sims travel farther from the origin, so compress them 2X as much\n",
    "fbm_x = fbm_x / (fold_compression * 2)\n",
    "fbm_y = fbm_y / (fold_compression * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Crop outlier tracks that wander very far from the origin\n",
    "# This allows for use of smaller motion cubes, preventing a few\n",
    "# outlier cubes from 'diluting' the feature space of most cubes\n",
    "# with a bunch of empty pixels\n",
    "rw_x, rw_y = crop_tracks(rw_x, rw_y, lbound=64, hbound=78)\n",
    "pf_x, pf_y = crop_tracks(pf_x, pf_y, lbound=64, hbound=78)\n",
    "fbm_x, fbm_y = crop_tracks(fbm_x, fbm_y, lbound=64, hbound=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform class balancing\n",
    "min_class = min(rw_x.shape[0], pf_x.shape[0], fbm_x.shape[0])\n",
    "min_class = 15000\n",
    "rw_x, rw_y = rw_x[:min_class, :], rw_y[:min_class,:]\n",
    "pf_x, pf_y = pf_x[:min_class, :], pf_y[:min_class,:]\n",
    "fbm_x, fbm_y = fbm_x[:min_class, :], fbm_y[:min_class,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set cube size\n",
    "x_max, y_max = 156, 156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify a position marker to use as a 2D ndarray. \n",
    "# Binary disks seem to work well as position markers, and broad\n",
    "# Gaussians have also been effectacious.\n",
    "width = 25\n",
    "sigma = 20\n",
    "staticK = np.zeros([x_max*2, y_max*2]) # kernel must be 2X size of cube\n",
    "staticK[x_max,y_max] = 1\n",
    "se = disk(width)\n",
    "staticK = ndi.binary_dilation(staticK, structure=se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate motion cubes\n",
    "rw_cubes = motion_cube(rw_x, rw_y, x_max, y_max, staticK=staticK, binary=True, save=rw_dir)\n",
    "pf_cubes = motion_cube(pf_x, pf_y, x_max, y_max, staticK=staticK, binary=True, save=pf_dir)\n",
    "fbm_cubes = motion_cube(fbm_x, fbm_y, x_max, y_max, staticK=staticK, binary=True, save=fbm_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
